{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d299ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to create DataFrame \n",
    "import pandas as pd\n",
    "\n",
    "#Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "271b7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DataFrame of the given data \n",
    "train = pd.read_csv('train.csv')\n",
    "valid = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048ea9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>-0.021332</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.212557</td>\n",
       "      <td>0.099683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085248</td>\n",
       "      <td>-0.096007</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>-0.041432</td>\n",
       "      <td>0.094806</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113040</td>\n",
       "      <td>0.175731</td>\n",
       "      <td>0.217741</td>\n",
       "      <td>-0.196254</td>\n",
       "      <td>-0.010129</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>-0.239192</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090283</td>\n",
       "      <td>-0.053885</td>\n",
       "      <td>-0.010967</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>-0.122958</td>\n",
       "      <td>0.192949</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.091281</td>\n",
       "      <td>0.160776</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>-0.050092</td>\n",
       "      <td>-0.045661</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021524</td>\n",
       "      <td>-0.008411</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.173831</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.065046</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071936</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>-0.121892</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>-0.065965</td>\n",
       "      <td>-0.088732</td>\n",
       "      <td>-0.082243</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>-0.341500</td>\n",
       "      <td>0.142430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155621</td>\n",
       "      <td>-0.079447</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-0.151966</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.031138   0.079892   0.157382  -0.014636  -0.051778  -0.021332   \n",
       "1   0.113040   0.175731   0.217741  -0.196254  -0.010129  -0.030586   \n",
       "2   0.048570   0.091281   0.160776  -0.150937   0.020115   0.044117   \n",
       "3   0.039212   0.118388   0.173831  -0.096659  -0.008702   0.061298   \n",
       "4   0.056019   0.170639   0.157917  -0.228605  -0.065965  -0.088732   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0  -0.073593  -0.005386  -0.212557    0.099683  ...    -0.085248    -0.096007   \n",
       "1   0.067114  -0.072412  -0.239192    0.104741  ...    -0.090283    -0.053885   \n",
       "2  -0.050092  -0.045661  -0.155332    0.117206  ...    -0.021524    -0.008411   \n",
       "3   0.008974  -0.003277  -0.065046    0.095480  ...    -0.071936    -0.023120   \n",
       "4  -0.082243  -0.080568  -0.341500    0.142430  ...    -0.155621    -0.079447   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0    -0.000766     0.021399    -0.041432     0.094806       45      NaN   \n",
       "1    -0.010967     0.062209    -0.122958     0.192949       45      NaN   \n",
       "2    -0.006248     0.031468    -0.056915     0.154731       45      NaN   \n",
       "3    -0.007812     0.057600    -0.121892     0.072796       45      NaN   \n",
       "4     0.015316     0.127726    -0.151966     0.169634       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd01976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1        0\n",
       "feature_2        0\n",
       "feature_3        0\n",
       "feature_4        0\n",
       "feature_5        0\n",
       "              ... \n",
       "feature_768      0\n",
       "label_1          0\n",
       "label_2        480\n",
       "label_3          0\n",
       "label_4          0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking provided data\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1fa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dependent & Independent features\n",
    "y = train[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "y_valid = valid[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x = train.drop(y, axis=1)\n",
    "x_valid = valid.drop(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b85cc13",
   "metadata": {},
   "source": [
    "# Model Checking & Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f7d21",
   "metadata": {},
   "source": [
    "For KNN, I used Grid Search to do hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9940ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_knn(train_x, train_y, vaid_x, valid_y):\n",
    "    grid_params = { 'n_neighbors' : [3,5,7,15],\n",
    "               'weights' : ['uniform','distance']}\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "    g_res = gs.fit(train_x, train_y)\n",
    "    print(f\"Best Hyperparameters:\",gs.best_params_)\n",
    "    # Get the best k-NN model with the optimal hyperparameters\n",
    "    best_knn = gs.best_estimator_\n",
    "    # Evaluate the best model on the test data\n",
    "    accuracy = best_knn.score(vaid_x, valid_y)\n",
    "    print(f\"Accuracy for KNN {accuracy}\")      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488e15b",
   "metadata": {},
   "source": [
    "Due to performance restriction of my machine, I do hyperparameter tuning manually for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cfe74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def try_svm(train_x, train_y, vaid_x, valid_y):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with default settings (RBF - exponential kernal) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.LinearSVC(dual=\"auto\")\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of Linear SVM (one-vs-the-rest) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with linear kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with sigmoid kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 2 \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 3 \", accuracy_score(valid_y, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8872dc3",
   "metadata": {},
   "source": [
    "Logistic Regression Model\n",
    "Checking Hyper Parameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2215bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def try_logistic(train_x, train_y, vaid_x, valid_y):\n",
    "    for i in [\"lbfgs\",\"newton-cg\",\"sag\",\"saga\"]:\n",
    "        logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        logistic_regression.fit(train_x,train_y)\n",
    "        y_pred = logistic_regression.predict(vaid_x)\n",
    "        print(f\"Accuracy Score of Logistic Regression with solver {i}\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c5c39",
   "metadata": {},
   "source": [
    "Naive Bayes \n",
    "Trying out different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c6bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def try_naive(train_x, train_y, vaid_x, valid_y):\n",
    "    \n",
    "    min_value = np.min(train_x)\n",
    "    scaled_train_x = train_x - min_value\n",
    "    scaled_vaid_x = vaid_x - min_value\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with Gaussian Naive Bayes\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with MultinomialNB\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = ComplementNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with ComplementNB\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = CategoricalNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with CategoricalNB\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with BernoulliNB\", accuracy_score(valid_y, y_pred))  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f683f8",
   "metadata": {},
   "source": [
    "DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2b570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def try_decisionTree(train_x, train_y, vaid_x, valid_y):\n",
    "    # Initialize and train the Decision Tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Decision Tree\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43829835",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c869ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def try_random_forest(train_x, train_y, vaid_x, valid_y):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Random Forest\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236af1df",
   "metadata": {},
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f65aa6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.0-py3-none-win_amd64.whl (99.7 MB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#installing XG Boost\n",
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6e9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def try_xgBoost(train_x, train_y, vaid_x, valid_y):\n",
    "    # Create an XGBoost classifier for multi-class classification\n",
    "    clf = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Set the objective for multi-class classification\n",
    "    num_class=len(np.unique(train_y)),  # Number of classes\n",
    "    random_state=42\n",
    "    )\n",
    "    le = LabelEncoder()\n",
    "    train_y = le.fit_transform(train_y)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    print(f\"Accuracy Score of XG Boost\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9200395",
   "metadata": {},
   "source": [
    "# Feature Engineering Using Mutual Info Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa2e7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def select_cols_using_mutual_info_regression(x,y,n) :\n",
    "    selected_columns = SelectKBest(mutual_info_classif, k=n)\n",
    "    selected_columns.fit(x, y)\n",
    "    return x.columns[selected_columns.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3fd93ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_1'],300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e54ed027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After reducing rows, I got poor validation accuracy, So I decided to not to use this method.\n",
    "#x = x[selected_cols]\n",
    "#x_valid = x_valid[selected_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26bd1b",
   "metadata": {},
   "source": [
    "# Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70d5f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.764\n"
     ]
    }
   ],
   "source": [
    "#Doing Hyper parameter tuning for KNN & checking the best accuracy for label 1\n",
    "try_knn(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24cb0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.7733333333333333\n",
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.9453333333333334\n",
      "Accuracy Score of SVM with linear kernal function  0.8946666666666667\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.18533333333333332\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.696\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.696\n"
     ]
    }
   ],
   "source": [
    "#Checking SVM Values for Label 1\n",
    "try_svm(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae1eabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.8413333333333334\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.8413333333333334\n",
      "Accuracy Score of Logistic Regression with solver sag 0.8413333333333334\n",
      "Accuracy Score of Logistic Regression with solver saga 0.8413333333333334\n"
     ]
    }
   ],
   "source": [
    "#Checking Logistic Regression Values for Label1. It provided very good results. \n",
    "try_logistic(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa2fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.136\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.016\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.1\n",
      "Accuracy Score of Naive Bayes with CategoricalNB 0.03866666666666667\n",
      "Accuracy Score of Naive Bayes with BernoulliNB 0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "#It gave bad results\n",
    "try_naive(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16354f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.29733333333333334\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fa9bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.76\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a17cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.832\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b321d",
   "metadata": {},
   "source": [
    "When considering validation accuracy results of label 1, Linear SVM overperforms all. So it is better to use that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9dcac",
   "metadata": {},
   "source": [
    "# Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "326aafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.984\n"
     ]
    }
   ],
   "source": [
    "try_knn(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "488dbf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.9933333333333333\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.9933333333333333\n",
      "Accuracy Score of Logistic Regression with solver sag 0.9933333333333333\n",
      "Accuracy Score of Logistic Regression with solver saga 0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "try_logistic(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d316e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.992\n",
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.9946666666666667\n",
      "Accuracy Score of SVM with linear kernal function  0.9933333333333333\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.7133333333333334\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.9893333333333333\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.9893333333333333\n"
     ]
    }
   ],
   "source": [
    "try_svm(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3726f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.46266666666666667\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.8106666666666666\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.5906666666666667\n",
      "Accuracy Score of Naive Bayes with CategoricalNB 0.8106666666666666\n",
      "Accuracy Score of Naive Bayes with BernoulliNB 0.808\n"
     ]
    }
   ],
   "source": [
    "try_naive(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90c0140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.884\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1013f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.964\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9af867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.988\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96907411",
   "metadata": {},
   "source": [
    "When considering validation accuracy results of label 4, KNN, Logistic Regression and SVM  provided good accuracy. Since accuracies are close to 0. We can use Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a220f10f",
   "metadata": {},
   "source": [
    "# Label 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5633b",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance using SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65f0d5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     19938\n",
       "2      1449\n",
       "0       955\n",
       "12      954\n",
       "7       938\n",
       "13      482\n",
       "1       481\n",
       "11      480\n",
       "10      480\n",
       "3       479\n",
       "5       478\n",
       "9       472\n",
       "4       469\n",
       "8       465\n",
       "Name: label_4, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[\"label_4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ceb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27101eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since 6 value affects class balance property. We decided to undersample it.\n",
    "from imblearn.over_sampling  import SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(x, y[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93648585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     19938\n",
       "13    19938\n",
       "4     19938\n",
       "5     19938\n",
       "1     19938\n",
       "2     19938\n",
       "7     19938\n",
       "3     19938\n",
       "0     19938\n",
       "12    19938\n",
       "9     19938\n",
       "8     19938\n",
       "11    19938\n",
       "10    19938\n",
       "Name: label_4, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()\n",
    "#However resampled values gave poor performance. So I avoided using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac479bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "try_knn(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdac4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.8226666666666667\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.8226666666666667\n",
      "Accuracy Score of Logistic Regression with solver sag 0.8226666666666667\n",
      "Accuracy Score of Logistic Regression with solver saga 0.8226666666666667\n"
     ]
    }
   ],
   "source": [
    "try_logistic(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b060fc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.776\n",
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.8786666666666667\n",
      "Accuracy Score of SVM with linear kernal function  0.852\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.668\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.7746666666666666\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.7746666666666666\n"
     ]
    }
   ],
   "source": [
    "try_svm(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c3ea74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.084\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.6053333333333333\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.532\n",
      "Accuracy Score of Naive Bayes with CategoricalNB 0.7093333333333334\n",
      "Accuracy Score of Naive Bayes with BernoulliNB 0.7106666666666667\n"
     ]
    }
   ],
   "source": [
    "try_naive(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a90ff94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.6453333333333333\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06ec5159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d05d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.8853333333333333\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c664d16",
   "metadata": {},
   "source": [
    "When considering validation accuracy results of label 4, KNN, XG Boost and SVM  provided good accuracy. We can use ensambled method consisting above classifiers to predict values for our test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e274b3a",
   "metadata": {},
   "source": [
    "# Label 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687526f8",
   "metadata": {},
   "source": [
    "# Handling Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ea3af",
   "metadata": {},
   "source": [
    "Since i am handling each feature separately, I thought removing the rows which have empty values for label 2, is the best way to handle the missing values for label 2 as no artifical entries will not be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbcb3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_2 = train.dropna(subset=['label_2'])\n",
    "valid_label_2 = valid.dropna(subset=['label_2'])\n",
    "y_label_2 = data_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x_label_2 = data_label_2.drop(y_label_2, axis=1)\n",
    "y_label_2_valid = valid_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x_label_2_valid = valid_label_2.drop(y_label_2_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9169c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.7853260869565217\n"
     ]
    }
   ],
   "source": [
    "try_knn(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45446d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.6005434782608695\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.6005434782608695\n",
      "Accuracy Score of Logistic Regression with solver sag 0.6005434782608695\n",
      "Accuracy Score of Logistic Regression with solver saga 0.6005434782608695\n"
     ]
    }
   ],
   "source": [
    "try_logistic(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086171f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.6100543478260869\n",
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.7554347826086957\n",
      "Accuracy Score of SVM with linear kernal function  0.7377717391304348\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.1331521739130435\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.5176630434782609\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.5176630434782609\n"
     ]
    }
   ],
   "source": [
    "try_svm(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ab1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.12771739130434784\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.14266304347826086\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.18478260869565216\n",
      "Accuracy Score of Naive Bayes with CategoricalNB 0.16168478260869565\n",
      "Accuracy Score of Naive Bayes with BernoulliNB 0.16032608695652173\n"
     ]
    }
   ],
   "source": [
    "try_naive(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a46eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.29483695652173914\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7dcb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.6875\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a57f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.7989130434782609\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8af0c",
   "metadata": {},
   "source": [
    "Here KNN, Linear SVM, XG Boost models performed well beating other models. So here we can use ensamble of those models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a155629",
   "metadata": {},
   "source": [
    "# Evaluating test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d12768a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b3e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(\"ID\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff209d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_764    0\n",
       "feature_765    0\n",
       "feature_766    0\n",
       "feature_767    0\n",
       "feature_768    0\n",
       "Length: 768, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking provided data\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a6ad964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_contiguous = np.ascontiguousarray(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33659d2",
   "metadata": {},
   "source": [
    "# Label 1 - Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "973dd5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(dual=\"auto\")\n",
    "clf.fit(x, y[\"label_1\"])\n",
    "X_test_contiguous = np.ascontiguousarray(test)\n",
    "y_pred_label_1 = clf.predict(X_test_contiguous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ef2dc",
   "metadata": {},
   "source": [
    "# Label 3 - SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d77ec561",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(dual=\"auto\")\n",
    "clf.fit(x, y[\"label_3\"])\n",
    "y_pred_label_3 = clf.predict(X_test_contiguous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed957a0",
   "metadata": {},
   "source": [
    "# Label 2 -  Ensamble Method of SVM, XG Boost, KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "561fb72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8233695652173914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize the models\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Set the objective for multi-class classification\n",
    "    num_class=len(np.unique(y_label_2)),  # Number of classes\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('knn', knn_model),\n",
    "    ('xgb', xgb_model)\n",
    "], voting='hard')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_label_21 = le.fit_transform(y_label_2[\"label_2\"])\n",
    "ensemble_model.fit(x_label_2, y_label_21)\n",
    "y_pred_21 = ensemble_model.predict(np.ascontiguousarray(x_label_2_valid))\n",
    "y_pred_21 = le.inverse_transform(y_pred_21)\n",
    "ensemble_accuracy = accuracy_score(y_label_2_valid[\"label_2\"], y_pred_21)\n",
    "print(ensemble_accuracy)\n",
    "#ensemble_model.fit(x_label_2, train_y_encoded_2)\n",
    "#ensemble_predictions = ensemble_model.predict(X_test_contiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2e4f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label_2 = ensemble_model.predict(X_test_contiguous)\n",
    "y_pred_label_2 = le.inverse_transform(y_pred_label_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d101c62",
   "metadata": {},
   "source": [
    "# Label 4 - Ensamble Method of SVM, Logistic Regression, KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3fdd4",
   "metadata": {},
   "source": [
    "Checking Using Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d95200b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize the models\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "svm_model = svm.LinearSVC(dual=\"auto\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Set the objective for multi-class classification\n",
    "    num_class=len(np.unique(y[\"label_4\"])),  # Number of classes\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('knn', knn_model),\n",
    "    ('svm', svm_model),\n",
    "    ('xgb', xgb_model)\n",
    "], voting='hard')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_label_21 = le.fit_transform(y[\"label_4\"])\n",
    "ensemble_model.fit(x, y_label_21)\n",
    "y_pred_21 = ensemble_model.predict(np.ascontiguousarray(x_valid))\n",
    "y_pred_21 = le.inverse_transform(y_pred_21)\n",
    "ensemble_accuracy = accuracy_score(y_valid[\"label_4\"], y_pred_21)\n",
    "print(ensemble_accuracy)\n",
    "#ensemble_model.fit(x_label_2, train_y_encoded_2)\n",
    "#ensemble_predictions = ensemble_model.predict(X_test_contiguous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149f0ee",
   "metadata": {},
   "source": [
    "Since Ensamble accuracy is greater than individual accuracy, I decide to use this method for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cb4b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label_4 = ensemble_model.predict(X_test_contiguous)\n",
    "y_pred_label_4 = le.inverse_transform(y_pred_label_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ca5f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([ pd.Series(y_pred_label_1,name='label_1'), pd.Series(y_pred_label_2,name='label_2'), pd.Series(y_pred_label_3,name='label_3'), pd.Series(y_pred_label_4,name='label_4')], axis=1)\n",
    "\n",
    "# Reset the index and add an incrementing ID column\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "combined_df['ID'] = combined_df.index + 1\n",
    "\n",
    "# Reorder the columns with 'ID' as the leftmost column\n",
    "combined_df = combined_df[['ID'] + [col for col in combined_df.columns if col != 'ID']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f378c93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>740</td>\n",
       "      <td>20</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>741</td>\n",
       "      <td>35</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>742</td>\n",
       "      <td>54</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>743</td>\n",
       "      <td>38</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>744</td>\n",
       "      <td>51</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label_1  label_2  label_3  label_4\n",
       "0      1       26     22.0        0        2\n",
       "1      2       18     25.0        1        6\n",
       "2      3       16     30.0        1        6\n",
       "3      4        7     27.0        1        6\n",
       "4      5       58     29.0        0        6\n",
       "..   ...      ...      ...      ...      ...\n",
       "739  740       20     24.0        1        6\n",
       "740  741       35     24.0        1        2\n",
       "741  742       54     27.0        1        6\n",
       "742  743       38     32.0        1       12\n",
       "743  744       51     23.0        1        6\n",
       "\n",
       "[744 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91123d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "file_path = \"190199A_layer_11.csv\"  # Replace 'your_file_name.csv' with the desired file name and path\n",
    "\n",
    "# Use the to_csv method to save the DataFrame to a CSV file\n",
    "combined_df.to_csv(file_path, index=False)  # Set index to False if you don't want to save the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9297015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
