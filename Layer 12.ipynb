{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d299ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to create DataFrame \n",
    "import pandas as pd\n",
    "\n",
    "#Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "271b7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DataFrame of the given data \n",
    "train = pd.read_csv('train.csv')\n",
    "valid = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "048ea9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>-0.021332</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.212557</td>\n",
       "      <td>0.099683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085248</td>\n",
       "      <td>-0.096007</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>-0.041432</td>\n",
       "      <td>0.094806</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113040</td>\n",
       "      <td>0.175731</td>\n",
       "      <td>0.217741</td>\n",
       "      <td>-0.196254</td>\n",
       "      <td>-0.010129</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>-0.239192</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090283</td>\n",
       "      <td>-0.053885</td>\n",
       "      <td>-0.010967</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>-0.122958</td>\n",
       "      <td>0.192949</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.091281</td>\n",
       "      <td>0.160776</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>-0.050092</td>\n",
       "      <td>-0.045661</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021524</td>\n",
       "      <td>-0.008411</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.173831</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.065046</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071936</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>-0.121892</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>-0.065965</td>\n",
       "      <td>-0.088732</td>\n",
       "      <td>-0.082243</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>-0.341500</td>\n",
       "      <td>0.142430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155621</td>\n",
       "      <td>-0.079447</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-0.151966</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.031138   0.079892   0.157382  -0.014636  -0.051778  -0.021332   \n",
       "1   0.113040   0.175731   0.217741  -0.196254  -0.010129  -0.030586   \n",
       "2   0.048570   0.091281   0.160776  -0.150937   0.020115   0.044117   \n",
       "3   0.039212   0.118388   0.173831  -0.096659  -0.008702   0.061298   \n",
       "4   0.056019   0.170639   0.157917  -0.228605  -0.065965  -0.088732   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0  -0.073593  -0.005386  -0.212557    0.099683  ...    -0.085248    -0.096007   \n",
       "1   0.067114  -0.072412  -0.239192    0.104741  ...    -0.090283    -0.053885   \n",
       "2  -0.050092  -0.045661  -0.155332    0.117206  ...    -0.021524    -0.008411   \n",
       "3   0.008974  -0.003277  -0.065046    0.095480  ...    -0.071936    -0.023120   \n",
       "4  -0.082243  -0.080568  -0.341500    0.142430  ...    -0.155621    -0.079447   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0    -0.000766     0.021399    -0.041432     0.094806       45      NaN   \n",
       "1    -0.010967     0.062209    -0.122958     0.192949       45      NaN   \n",
       "2    -0.006248     0.031468    -0.056915     0.154731       45      NaN   \n",
       "3    -0.007812     0.057600    -0.121892     0.072796       45      NaN   \n",
       "4     0.015316     0.127726    -0.151966     0.169634       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd01976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_1        0\n",
      "feature_2        0\n",
      "feature_3        0\n",
      "feature_4        0\n",
      "feature_5        0\n",
      "              ... \n",
      "feature_768      0\n",
      "label_1          0\n",
      "label_2        480\n",
      "label_3          0\n",
      "label_4          0\n",
      "Length: 772, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking provided data\n",
    "null_counts = train.isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9256a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dependent & Independent features\n",
    "y = train[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "y_valid = valid[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x = train.drop(y, axis=1)\n",
    "x_valid = valid.drop(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5af9a",
   "metadata": {},
   "source": [
    "# Model Checking & Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83800d55",
   "metadata": {},
   "source": [
    "For KNN, I used Grid Search to do hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9940ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_knn(train_x, train_y, vaid_x, valid_y):\n",
    "    grid_params = { 'n_neighbors' : [3,5,7,15],\n",
    "               'weights' : ['uniform','distance']}\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "    g_res = gs.fit(train_x, train_y)\n",
    "    print(f\"Best Hyperparameters:\",gs.best_params_)\n",
    "    # Get the best k-NN model with the optimal hyperparameters\n",
    "    best_knn = gs.best_estimator_\n",
    "    # Evaluate the best model on the test data\n",
    "    accuracy = best_knn.score(vaid_x, valid_y)\n",
    "    print(f\"Accuracy for KNN {accuracy}\")      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf89391",
   "metadata": {},
   "source": [
    "Due to performance restriction of my machine, I do hyperparameter tuning manually for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cfe74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def try_svm(train_x, train_y, vaid_x, valid_y):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with default settings (RBF - exponential kernal) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "#     clf = svm.LinearSVC(dual=\"auto\")\n",
    "#     clf.fit(train_x, train_y)\n",
    "#     X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "#     y_pred = clf.predict(X_valid_contiguous)\n",
    "#     print(f\"Accuracy Score of Linear SVM (one-vs-the-rest) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with linear kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with sigmoid kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 2 \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(vaid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 3 \", accuracy_score(valid_y, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163f8b6",
   "metadata": {},
   "source": [
    "Logistic Regression Model\n",
    "Checking Hyper Parameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2215bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def try_logistic(train_x, train_y, vaid_x, valid_y):\n",
    "    for i in [\"lbfgs\",\"newton-cg\",\"sag\",\"saga\"]:\n",
    "        logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        logistic_regression.fit(train_x,train_y)\n",
    "        y_pred = logistic_regression.predict(vaid_x)\n",
    "        print(f\"Accuracy Score of Logistic Regression with solver {i}\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8fab8",
   "metadata": {},
   "source": [
    "Naive Bayes \n",
    "Trying out different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2c6bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def try_naive(train_x, train_y, vaid_x, valid_y):\n",
    "    \n",
    "    min_value = np.min(train_x)\n",
    "    scaled_train_x = train_x - min_value\n",
    "    scaled_vaid_x = vaid_x - min_value\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with Gaussian Naive Bayes\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with MultinomialNB\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = ComplementNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with ComplementNB\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "#     clf = CategoricalNB()\n",
    "#     clf.fit(scaled_train_x, train_y)\n",
    "#     y_pred = clf.predict(scaled_vaid_x)\n",
    "#     print(f\"Accuracy Score of Naive Bayes with CategoricalNB\", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(scaled_train_x, train_y)\n",
    "    y_pred = clf.predict(scaled_vaid_x)\n",
    "    print(f\"Accuracy Score of Naive Bayes with BernoulliNB\", accuracy_score(valid_y, y_pred))  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024bd87f",
   "metadata": {},
   "source": [
    "DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2b570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def try_decisionTree(train_x, train_y, vaid_x, valid_y):\n",
    "    # Initialize and train the Decision Tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Decision Tree\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d27eb1",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c869ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def try_random_forest(train_x, train_y, vaid_x, valid_y):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Random Forest\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c74182",
   "metadata": {},
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65aa6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.24.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.10.0)\n",
      "\u001b[33mDEPRECATION: h2o-mlops-client main has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of h2o-mlops-client or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#installing XG Boost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf6e9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def try_xgBoost(train_x, train_y, vaid_x, valid_y):\n",
    "    # Create an XGBoost classifier for multi-class classification\n",
    "    clf = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Set the objective for multi-class classification\n",
    "    num_class=len(np.unique(y)),  # Number of classes\n",
    "    random_state=42\n",
    "    )\n",
    "    le = LabelEncoder()\n",
    "    train_y = le.fit_transform(train_y)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    print(f\"Accuracy Score of XG Boost\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4e02d",
   "metadata": {},
   "source": [
    "# Feature Engineering Using Mutual Info Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2e7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def select_cols_using_mutual_info_regression(x,y,n) :\n",
    "    selected_columns = SelectKBest(mutual_info_classif, k=n)\n",
    "    selected_columns.fit(x, y)\n",
    "    return x.columns[selected_columns.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3fd93ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_1'],300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e54ed027",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[selected_cols]\n",
    "x_valid = x_valid[selected_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6723",
   "metadata": {},
   "source": [
    "# Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70d5f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.24266666666666667\n"
     ]
    }
   ],
   "source": [
    "#Doing Hyper parameter tuning for KNN & checking the best accuracy for label 1\n",
    "try_knn(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.016\n",
      "Accuracy Score of SVM with linear kernal function  0.176\n"
     ]
    }
   ],
   "source": [
    "#Checking SVM Values for Label 1\n",
    "try_svm(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Logistic Regression Values for Label1. It provided very good results. \n",
    "try_logistic(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fa2fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.016\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.016\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.05333333333333334\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#It gave bad results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtry_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mtry_naive\u001b[0;34m(train_x, train_y, vaid_x, valid_y)\u001b[0m\n\u001b[1;32m     28\u001b[0m clf \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[1;32m     29\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(scaled_train_x, train_y)\n\u001b[0;32m---> 30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_vaid_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy Score of Naive Bayes with CategoricalNB\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(valid_y, y_pred))\n\u001b[1;32m     33\u001b[0m clf \u001b[38;5;241m=\u001b[39m BernoulliNB()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:81\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m---> 81\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:1425\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[1;32m   1424\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[0;32m-> 1425\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1426\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "#It gave bad results\n",
    "try_naive(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16354f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fa9bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.056\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9dfde62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.064\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x,y[\"label_1\"],x_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74201cc",
   "metadata": {},
   "source": [
    "When considering validation accuracy results of label 1, Linear SVM and Logistic Regression gave good results, We can use Linear SVM model for our test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "446242fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>0.104941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.060278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302    0.077971  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288    0.066863  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283    0.042701  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217    0.104941  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422    0.060278  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.drop([\"ID\"], axis=1)\n",
    "test.head()\n",
    "# test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a65caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28520, 300)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "559038ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.24\n",
      "[26 18 16  7 58 46  7 22 29 26 33 32 54 51 22 48 23  2 43 42 11 35 39 34\n",
      " 21 13 28 55  2 51 55 16  1 56 30 29 31  6 51 18 19 47  6 46 59 25 31 18\n",
      "  5 32 25 56 39 37 32 40  5 52 28 34 32 47 55 24 23 18 20  6 36 38 22 26\n",
      " 44 46 55 36 49 53 57 12 52 38 23 27 33 49 14 19 12 39 36 43 34 32 54 46\n",
      " 27  5  7 42 19 26 31 36 53 10 12 38 38  2 57 14  7 50 46 46 17 34 30 40\n",
      " 48 40  8 22 38 15 13  9 52  5 40 13 10 55 28 25 42 57 16 27 51 21 51 27\n",
      " 32 33 16  3 11 46 42 37 47 50  3 48 19 20 15  8  5 18  5 28 46 60 50 40\n",
      " 17 32 45 57 42 16 11 35 34 52 41 21  7  8 21 19 37 55 20 28 23 35 46 52\n",
      " 30 27  1  8 28 37  3 36 17 60 18  3 22  9 43 25 17 26 19 36 36 21  1 58\n",
      " 39 47 38  6 50 39 23  5 48 22 58 15 30 38 18 54  8 41 16  8 43 21  8 52\n",
      " 10 16 47 20 15 51 56 11 16 48 50 51 10 51 31  6  9 31 57 22  5 11 11 43\n",
      "  8  7 58 23 50 58 13 13 47 50 60 50 47 36 28 36 53 39 34 32  5  2 19 53\n",
      " 57 50 30 32 41 37 41 51 20 20 31 21 44 31 15 40 46 39 21 25 31 44 54 34\n",
      " 46 57 43 53 26  8 17  5 31 12  8 32 59 49 56 17 26 49 54 10  9  3 36 39\n",
      " 33 18 54 29 23 10 11 47 37 33 48 35 25 27  4 51 12 33 42 48 44 23  6 12\n",
      " 30 40 56 31  8 44 15 59 58 39 29 28  7 15  3 59 37 40  3 60 58  9 10 31\n",
      " 60 23  7 15 18  7 11 37  2 23 41  4 54 39 40 53 42 20 21 35 31 58  6 29\n",
      " 52 29 48 40 24 50 28 47 50 27 20 44 24  8 38 51 37 23  8 18 11 13  8 15\n",
      " 29 39 11 39 31 58 60 52 30 31  5 29 33 10 48 21 51 21 37 55 19 49 60 38\n",
      " 28  6 17 11 40 17 30  1  4 36 30 58 57 53 18 37 52 25 14 13 13 30 41 57\n",
      " 25 16 43 36 13 43 23 37 29  6 37 13 53 24 13 29 31 35 13 27  5 22 22 49\n",
      "  9 54 56 12 30 56 57 40 32 16 37 41 26 41 42 11 36 47 23 16 29 18 47 23\n",
      " 22 55 27 33  3 40 40 18 31  1  7 59 28 44 29 57  3 39 37 27 34 32 57 44\n",
      " 37 38  2 22 33 53 36 41 19 55  7 33 55 27 48 30 24 54 26 36 15 35 17 16\n",
      "  4 17 27 10 12 33  6 47 21 10 48 55 16 42 39  4 24 39 16 33 43 41  1 49\n",
      " 46 24 40 14 19 18 43 29 57 16 25  1  2 49 59 18  8 37 32 32 57 23 25 30\n",
      " 26 16 11  9 12 15 11 19 37 53 19  8 17 17  4 34 22 32 27 15  3 25 50  8\n",
      " 20 30 13 25 60 40 11 37  2 44 55 52 31 34  2 59 24 39 54 37 43  1 32 50\n",
      " 51  9 32  5 48  1 46 37 19 24 38 59  6 51 20 14 51  2 60 10 42 48 11 43\n",
      " 39  8 50 30 15  2  9  4 22 44 16 14 31 24 37 50  1 47 19 10 43 43 21 44\n",
      " 48 22 33 20 23 33 46 36 51  4 54 59 28 55 50 56 26 47 31 35 35 55 38 54]\n"
     ]
    }
   ],
   "source": [
    "# taken model for this lable is \n",
    "# Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
    "# Best Hyperparameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
    "# Accuracy for KNN 0.24266666666666667\n",
    "\n",
    "grid_params = { 'n_neighbors' : [3,5,7,15],\n",
    "               'weights' : ['uniform','distance']}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "g_res = gs.fit(x[300:], y[\"label_1\"][300:])\n",
    "print(f\"Best Hyperparameters:\",gs.best_params_)\n",
    "# Get the best k-NN model with the optimal hyperparameters\n",
    "best_knn = gs.best_estimator_\n",
    "# Evaluate the best model on the test data\n",
    "accuracy = best_knn.score(x_valid,y_valid[\"label_1\"])\n",
    "print(f\"Accuracy for KNN {accuracy}\")     \n",
    "\n",
    "pridiction = best_knn.predict(test)\n",
    "df = pd.DataFrame({'label_1': pridiction})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('label_1.csv', index=False)\n",
    "print(pridiction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9888890",
   "metadata": {},
   "source": [
    "# Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "326aafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Accuracy for KNN 0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "try_knn(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "488dbf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.8773333333333333\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.8773333333333333\n",
      "Accuracy Score of Logistic Regression with solver sag 0.8773333333333333\n",
      "Accuracy Score of Logistic Regression with solver saga 0.8773333333333333\n"
     ]
    }
   ],
   "source": [
    "try_logistic(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d316e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.8106666666666666\n",
      "Accuracy Score of SVM with linear kernal function  0.8653333333333333\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.7306666666666667\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.8706666666666667\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.8706666666666667\n"
     ]
    }
   ],
   "source": [
    "try_svm(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3726f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.8106666666666666\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.8106666666666666\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.816\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtry_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mtry_naive\u001b[0;34m(train_x, train_y, vaid_x, valid_y)\u001b[0m\n\u001b[1;32m     28\u001b[0m clf \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[1;32m     29\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(scaled_train_x, train_y)\n\u001b[0;32m---> 30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_vaid_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy Score of Naive Bayes with CategoricalNB\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(valid_y, y_pred))\n\u001b[1;32m     33\u001b[0m clf \u001b[38;5;241m=\u001b[39m BernoulliNB()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:81\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m---> 81\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:1425\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[1;32m   1424\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[0;32m-> 1425\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1426\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "try_naive(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90c0140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.5053333333333333\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1013f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.47333333333333333\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce9af867",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtry_xgBoost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mtry_xgBoost\u001b[0;34m(train_x, train_y, vaid_x, valid_y)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(train_x, train_y)\n\u001b[1;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(vaid_x)\n\u001b[0;32m---> 16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy Score of XG Boost\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(valid_y, y_pred))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:161\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(y, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)))\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[1;32m    162\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[y]\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [2]"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c13ee",
   "metadata": {},
   "source": [
    "When considering validation accuracy results of label 3, Logistic Regression, SVM provided good accuracy. Since we got good accuracy close to 100%, We can use Logistics Regression for our test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9d86222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.8653333333333333\n",
      "[0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1\n",
      " 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
      " 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# taken model for this lable is \n",
    "# Accuracy Score of SVM with linear kernal function  0.8773333333333333\n",
    "# try_logistic(x,y[\"label_3\"],x_valid,y_valid[\"label_3\"])\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "clf.fit(x, y[\"label_3\"])\n",
    "X_valid_contiguous = np.ascontiguousarray(x_valid)\n",
    "y_pred = clf.predict(X_valid_contiguous)\n",
    "print(f\"Accuracy Score of SVM with linear kernal function \", accuracy_score(y_valid[\"label_3\"], y_pred))\n",
    "\n",
    "pridiction = clf.predict(test)\n",
    "df = pd.DataFrame({'label_3': pridiction})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('label_3.csv', index=False)\n",
    "print(pridiction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534712e",
   "metadata": {},
   "source": [
    "# Label 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a662d68",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance using SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd99d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     19938\n",
       "2      1449\n",
       "0       955\n",
       "12      954\n",
       "7       938\n",
       "13      482\n",
       "1       481\n",
       "11      480\n",
       "10      480\n",
       "3       479\n",
       "5       478\n",
       "9       472\n",
       "4       469\n",
       "8       465\n",
       "Name: label_4, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[\"label_4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fd18f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imbalanced-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imbalanced-learn) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imbalanced-learn) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imbalanced-learn) (3.1.0)\n",
      "\u001b[33mDEPRECATION: h2o-mlops-client main has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of h2o-mlops-client or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac479bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.676\n"
     ]
    }
   ],
   "source": [
    "try_knn(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cdac4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.10933333333333334\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.10933333333333334\n",
      "Accuracy Score of Logistic Regression with solver sag 0.10933333333333334\n",
      "Accuracy Score of Logistic Regression with solver saga 0.10933333333333334\n"
     ]
    }
   ],
   "source": [
    "try_logistic(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b060fc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.7093333333333334\n",
      "Accuracy Score of SVM with linear kernal function  0.06266666666666666\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.396\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.10666666666666667\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.10666666666666667\n"
     ]
    }
   ],
   "source": [
    "try_svm(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c3ea74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.02266666666666667\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.5533333333333333\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.24666666666666667\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtry_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mtry_naive\u001b[0;34m(train_x, train_y, vaid_x, valid_y)\u001b[0m\n\u001b[1;32m     28\u001b[0m clf \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[1;32m     29\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(scaled_train_x, train_y)\n\u001b[0;32m---> 30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_vaid_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy Score of Naive Bayes with CategoricalNB\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(valid_y, y_pred))\n\u001b[1;32m     33\u001b[0m clf \u001b[38;5;241m=\u001b[39m BernoulliNB()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:81\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m---> 81\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/naive_bayes.py:1425\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[1;32m   1424\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[0;32m-> 1425\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1426\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "try_naive(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a90ff94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.12533333333333332\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06ec5159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.6866666666666666\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91d05d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.33066666666666666\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e642cc0",
   "metadata": {},
   "source": [
    "When considering validation accuracy results of label 4, We can use Random Forest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5b22061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.6866666666666666\n",
      "[26 18 16  7 58 46  7 22 29 26 33 32 54 51 22 48 23  2 43 42 11 35 39 34\n",
      " 21 13 28 55  2 51 55 16  1 56 30 29 31  6 51 18 19 47  6 46 59 25 31 18\n",
      "  5 32 25 56 39 37 32 40  5 52 28 34 32 47 55 24 23 18 20  6 36 38 22 26\n",
      " 44 46 55 36 49 53 57 12 52 38 23 27 33 49 14 19 12 39 36 43 34 32 54 46\n",
      " 27  5  7 42 19 26 31 36 53 10 12 38 38  2 57 14  7 50 46 46 17 34 30 40\n",
      " 48 40  8 22 38 15 13  9 52  5 40 13 10 55 28 25 42 57 16 27 51 21 51 27\n",
      " 32 33 16  3 11 46 42 37 47 50  3 48 19 20 15  8  5 18  5 28 46 60 50 40\n",
      " 17 32 45 57 42 16 11 35 34 52 41 21  7  8 21 19 37 55 20 28 23 35 46 52\n",
      " 30 27  1  8 28 37  3 36 17 60 18  3 22  9 43 25 17 26 19 36 36 21  1 58\n",
      " 39 47 38  6 50 39 23  5 48 22 58 15 30 38 18 54  8 41 16  8 43 21  8 52\n",
      " 10 16 47 20 15 51 56 11 16 48 50 51 10 51 31  6  9 31 57 22  5 11 11 43\n",
      "  8  7 58 23 50 58 13 13 47 50 60 50 47 36 28 36 53 39 34 32  5  2 19 53\n",
      " 57 50 30 32 41 37 41 51 20 20 31 21 44 31 15 40 46 39 21 25 31 44 54 34\n",
      " 46 57 43 53 26  8 17  5 31 12  8 32 59 49 56 17 26 49 54 10  9  3 36 39\n",
      " 33 18 54 29 23 10 11 47 37 33 48 35 25 27  4 51 12 33 42 48 44 23  6 12\n",
      " 30 40 56 31  8 44 15 59 58 39 29 28  7 15  3 59 37 40  3 60 58  9 10 31\n",
      " 60 23  7 15 18  7 11 37  2 23 41  4 54 39 40 53 42 20 21 35 31 58  6 29\n",
      " 52 29 48 40 24 50 28 47 50 27 20 44 24  8 38 51 37 23  8 18 11 13  8 15\n",
      " 29 39 11 39 31 58 60 52 30 31  5 29 33 10 48 21 51 21 37 55 19 49 60 38\n",
      " 28  6 17 11 40 17 30  1  4 36 30 58 57 53 18 37 52 25 14 13 13 30 41 57\n",
      " 25 16 43 36 13 43 23 37 29  6 37 13 53 24 13 29 31 35 13 27  5 22 22 49\n",
      "  9 54 56 12 30 56 57 40 32 16 37 41 26 41 42 11 36 47 23 16 29 18 47 23\n",
      " 22 55 27 33  3 40 40 18 31  1  7 59 28 44 29 57  3 39 37 27 34 32 57 44\n",
      " 37 38  2 22 33 53 36 41 19 55  7 33 55 27 48 30 24 54 26 36 15 35 17 16\n",
      "  4 17 27 10 12 33  6 47 21 10 48 55 16 42 39  4 24 39 16 33 43 41  1 49\n",
      " 46 24 40 14 19 18 43 29 57 16 25  1  2 49 59 18  8 37 32 32 57 23 25 30\n",
      " 26 16 11  9 12 15 11 19 37 53 19  8 17 17  4 34 22 32 27 15  3 25 50  8\n",
      " 20 30 13 25 60 40 11 37  2 44 55 52 31 34  2 59 24 39 54 37 43  1 32 50\n",
      " 51  9 32  5 48  1 46 37 19 24 38 59  6 51 20 14 51  2 60 10 42 48 11 43\n",
      " 39  8 50 30 15  2  9  4 22 44 16 14 31 24 37 50  1 47 19 10 43 43 21 44\n",
      " 48 22 33 20 23 33 46 36 51  4 54 59 28 55 50 56 26 47 31 35 35 55 38 54]\n"
     ]
    }
   ],
   "source": [
    "# taken model for this lable is \n",
    "# Accuracy Score of Random Forest 0.6866666666666666\n",
    "# try_random_forest(x,y[\"label_4\"],x_valid,y_valid[\"label_4\"])\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(x, y[\"label_4\"])\n",
    "y_pred = clf.predict(x_valid)\n",
    "print(f\"Accuracy Score of Random Forest\", accuracy_score(y_valid[\"label_4\"], y_pred))    \n",
    "\n",
    "pridiction = best_knn.predict(test)\n",
    "df = pd.DataFrame({'label_4': pridiction})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('label_4.csv', index=False)\n",
    "print(pridiction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a36689a",
   "metadata": {},
   "source": [
    "# Label 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a31c97",
   "metadata": {},
   "source": [
    "# Handling Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb307ccd",
   "metadata": {},
   "source": [
    "Since i am handling each feature separately, I thought removing the rows which have empty values for label 2, is the best way to handle the missing values for label 2 as no artifical entries will not be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbcb3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_2 = train.dropna(subset=['label_2'])\n",
    "valid_label_2 = valid.dropna(subset=['label_2'])\n",
    "y_label_2 = data_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x_label_2 = data_label_2.drop(y_label_2, axis=1)\n",
    "y_label_2_valid = valid_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x_label_2_valid = valid_label_2.drop(y_label_2_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9169c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.27445652173913043\n"
     ]
    }
   ],
   "source": [
    "try_knn(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45446d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.17119565217391305\n",
      "Accuracy Score of Logistic Regression with solver newton-cg 0.17119565217391305\n",
      "Accuracy Score of Logistic Regression with solver sag 0.17119565217391305\n",
      "Accuracy Score of Logistic Regression with solver saga 0.17119565217391305\n"
     ]
    }
   ],
   "source": [
    "try_logistic(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "086171f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.12092391304347826\n",
      "Accuracy Score of SVM with linear kernal function  0.13179347826086957\n",
      "Accuracy Score of SVM with sigmoid kernal function  0.06521739130434782\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.1480978260869565\n",
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.1480978260869565\n"
     ]
    }
   ],
   "source": [
    "try_svm(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55ab1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Naive Bayes with Gaussian Naive Bayes 0.06114130434782609\n",
      "Accuracy Score of Naive Bayes with MultinomialNB 0.08695652173913043\n",
      "Accuracy Score of Naive Bayes with ComplementNB 0.11277173913043478\n",
      "Accuracy Score of Naive Bayes with BernoulliNB 0.025815217391304348\n"
     ]
    }
   ],
   "source": [
    "try_naive(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a46eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree 0.09510869565217392\n"
     ]
    }
   ],
   "source": [
    "try_decisionTree(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b7dcb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.12092391304347826\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a57f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.11413043478260869\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d47a2d",
   "metadata": {},
   "source": [
    "Here KNN model performed well beating other models. So here we can use KNN model to predict label 2 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2fd4772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.27445652173913043\n",
      "[22. 25. 30. 27. 29. 28. 27. 33. 23. 22. 26. 23. 27. 26. 33. 26. 28. 25.\n",
      " 31. 29. 33. 24. 29. 25. 26. 27. 28. 23. 25. 26. 23. 30. 30. 24. 28. 23.\n",
      " 26. 25. 26. 25. 23. 23. 25. 30. 31. 22. 26. 25. 25. 23. 22. 24. 29. 27.\n",
      " 23. 26. 30. 34. 28. 25. 23. 23. 23. 26. 28. 25. 25. 25. 22. 32. 33. 22.\n",
      " 61. 30. 26. 26. 26. 24. 27. 26. 34. 32. 28. 31. 26. 26. 31. 23. 26. 29.\n",
      " 22. 31. 25. 23. 27. 30. 31. 25. 27. 29. 23. 22. 26. 22. 24. 36. 26. 32.\n",
      " 32. 25. 27. 31. 26. 24. 30. 30. 26. 25. 28. 26. 26. 26. 41. 33. 32. 28.\n",
      " 27. 35. 34. 28. 26. 27. 36. 23. 28. 22. 29. 27. 30. 31. 30. 26. 23. 31.\n",
      " 23. 30. 30. 31. 33. 30. 29. 27. 23. 24. 31. 26. 23. 25. 28. 41. 25. 25.\n",
      " 25. 28. 30. 27. 24. 26. 26. 23. 26. 27. 29. 30. 33. 24. 25. 34. 30. 23.\n",
      " 27. 41. 26. 23. 27. 23. 61. 28. 28. 24. 30. 34. 28. 31. 30. 41. 28. 27.\n",
      " 31. 22. 26. 27. 25. 31. 33. 35. 31. 22. 26. 22. 23. 22. 22. 26. 30. 30.\n",
      " 29. 23. 26. 25. 24. 29. 28. 25. 26. 33. 29. 28. 28. 32. 25. 27. 41. 30.\n",
      " 30. 41. 31. 26. 41. 24. 36. 30. 23. 25. 28. 26. 24. 33. 30. 26. 24. 26.\n",
      " 28. 26. 26. 25. 35. 26. 27. 33. 25. 33. 33. 31. 41. 27. 29. 24. 24. 29.\n",
      " 27. 27. 23. 24. 27. 30. 23. 22. 28. 22. 24. 29. 25. 23. 25. 25. 23. 24.\n",
      " 27. 24. 28. 23. 30. 27. 30. 26. 25. 25. 26. 26. 61. 26. 28. 26. 30. 29.\n",
      " 26. 22. 23. 61. 27. 25. 30. 27. 31. 24. 22. 41. 26. 25. 26. 26. 41. 23.\n",
      " 26. 26. 31. 26. 22. 26. 27. 36. 35. 31. 22. 29. 27. 30. 27. 23. 28. 36.\n",
      " 33. 23. 27. 26. 26. 24. 22. 31. 23. 26. 26. 26. 29. 26. 61. 28. 25. 26.\n",
      " 28. 26. 24. 26. 41. 61. 28. 31. 29. 29. 23. 28. 27. 28. 31. 31. 27. 26.\n",
      " 31. 27. 29. 29. 36. 26. 27. 28. 27. 28. 25. 27. 33. 24. 25. 28. 25. 23.\n",
      " 23. 29. 26. 24. 27. 25. 26. 24. 26. 29. 25. 23. 34. 23. 26. 26. 26. 24.\n",
      " 31. 23. 24. 31. 28. 61. 26. 41. 32. 26. 27. 28. 41. 25. 33. 27. 41. 28.\n",
      " 23. 29. 33. 29. 26. 29. 27. 34. 28. 26. 25. 23. 26. 36. 26. 26. 26. 26.\n",
      " 27. 23. 23. 26. 27. 32. 22. 25. 26. 33. 26. 26. 28. 25. 23. 22. 28. 29.\n",
      " 27. 24. 25. 27. 34. 31. 31. 27. 27. 28. 30. 27. 22. 30. 31. 22. 27. 31.\n",
      " 28. 27. 23. 25. 27. 27. 23. 26. 27. 23. 26. 24. 27. 31. 25. 33. 33. 26.\n",
      " 35. 27. 24. 26. 28. 24. 27. 29. 23. 30. 27. 30. 22. 30. 29. 33. 22. 23.\n",
      " 28. 30. 23. 25. 23. 28. 33. 23. 31. 26. 25. 26. 26. 25. 26. 30. 27. 31.\n",
      " 28. 61. 23. 27. 31. 29. 27. 26. 25. 23. 24. 61. 27. 32. 25. 33. 26. 24.\n",
      " 22. 30. 23. 23. 26. 26. 26. 31. 26. 28. 26. 27. 22. 22. 28. 24. 26. 30.\n",
      " 23. 26. 31. 36. 26. 26. 25. 23. 26. 36. 26. 23. 30. 29. 29. 23. 26. 29.\n",
      " 26. 26. 25. 30. 30. 26. 30. 23. 26. 31. 23. 25. 31. 23. 27. 30. 25. 30.\n",
      " 25. 26. 31. 25. 41. 27. 23. 23. 27. 23. 25. 28. 22. 30. 33. 35. 26. 28.\n",
      " 33. 23. 27. 24. 25. 41. 26. 26. 23. 25. 33. 23. 31. 28. 31. 22. 24. 41.\n",
      " 25. 28. 27. 22. 27. 26. 33. 27. 23. 61. 23. 34. 25. 25. 25. 31. 26. 29.\n",
      " 27. 27. 31. 30. 23. 24. 26. 35. 23. 29. 28. 27. 30. 23. 23. 26. 26. 31.\n",
      " 25. 26. 25. 31. 26. 25. 27. 36. 29. 26. 33. 31. 29. 41. 24. 28. 28. 25.\n",
      " 35. 23. 33. 61. 30. 26. 26. 26. 27. 24. 30. 23. 23. 36. 31. 31. 26. 61.\n",
      " 26. 33. 26. 25. 28. 26. 30. 26. 26. 23. 28. 31. 28. 23. 24. 24. 22. 41.\n",
      " 26. 24. 24. 30. 32. 27.]\n"
     ]
    }
   ],
   "source": [
    "# taken model for this lable is \n",
    "# Accuracy Score of SVM with linear kernal function  0.9746666666666667\n",
    "# try_knn(x_label_2,y_label_2[\"label_2\"],x_label_2_valid,y_label_2_valid[\"label_2\"])\n",
    "# Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
    "# Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
    "# Accuracy for KNN 0.27445652173913043\n",
    "\n",
    "\n",
    "\n",
    "grid_params = { 'n_neighbors' : [3,5,7,15],\n",
    "               'weights' : ['uniform','distance']}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "g_res = gs.fit(x_label_2, y_label_2[\"label_2\"])\n",
    "print(f\"Best Hyperparameters:\",gs.best_params_)\n",
    "# Get the best k-NN model with the optimal hyperparameters\n",
    "best_knn = gs.best_estimator_\n",
    "# Evaluate the best model on the test data\n",
    "accuracy = best_knn.score(x_label_2_valid,y_label_2_valid[\"label_2\"])\n",
    "print(f\"Accuracy for KNN {accuracy}\")     \n",
    "\n",
    "pridiction = best_knn.predict(test)\n",
    "df = pd.DataFrame({'label_2': pridiction})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('label_2.csv', index=False)\n",
    "print(pridiction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cc116",
   "metadata": {},
   "source": [
    "## Combine all CSV files for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3e5a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1_o = pd.read_csv('label_1.csv', header=None)[1:]\n",
    "label_2_o = pd.read_csv('label_2.csv', header=None)[1:]\n",
    "label_3_o = pd.read_csv('label_3.csv', header=None)[1:]\n",
    "label_4_o = pd.read_csv('label_4.csv', header=None)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd851d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    0\n",
       "..  ..\n",
       "740  1\n",
       "741  1\n",
       "742  1\n",
       "743  1\n",
       "744  1\n",
       "\n",
       "[744 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_3_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "602b89aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740</td>\n",
       "      <td>35</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741</td>\n",
       "      <td>35</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>55</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>743</td>\n",
       "      <td>38</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>744</td>\n",
       "      <td>54</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID label_1 label_2 label_3 label_4\n",
       "1      1      26    22.0       0      26\n",
       "2      2      18    25.0       1      18\n",
       "3      3      16    30.0       1      16\n",
       "4      4       7    27.0       1       7\n",
       "5      5      58    29.0       0      58\n",
       "..   ...     ...     ...     ...     ...\n",
       "740  740      35    24.0       1      35\n",
       "741  741      35    24.0       1      35\n",
       "742  742      55    30.0       1      55\n",
       "743  743      38    32.0       1      38\n",
       "744  744      54    27.0       1      54\n",
       "\n",
       "[744 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([label_1_o, label_2_o, label_3_o, label_4_o], axis=1)\n",
    "\n",
    "column_names = [\"label_1\", \"label_2\", \"label_3\", \"label_4\"]  # Replace with your desired column names\n",
    "combined_df.columns = column_names\n",
    "\n",
    "combined_df['ID'] = range(1, len(combined_df) + 1)\n",
    "\n",
    "column_order = ['ID',\"label_1\", \"label_2\", \"label_3\", \"label_4\"]\n",
    "\n",
    "# Use reindex to reorder the columns\n",
    "combined_df = combined_df.reindex(columns=column_order)\n",
    "\n",
    "combined_df.to_csv(\"combined_data.csv\",index=False)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0bb8d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label_1  label_2  label_3  label_4\n",
       "0   1       26     22.0        0       26\n",
       "1   2       18     25.0        1       18\n",
       "2   3       16     30.0        1       16\n",
       "3   4        7     27.0        1        7\n",
       "4   5       58     29.0        0       58"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv = pd.read_csv(\"combined_data.csv\")\n",
    "combined_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "703f6e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>740</td>\n",
       "      <td>35</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>741</td>\n",
       "      <td>35</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>742</td>\n",
       "      <td>55</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>743</td>\n",
       "      <td>38</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>744</td>\n",
       "      <td>54</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label_1  label_2  label_3  label_4\n",
       "0      1       26     22.0        0       26\n",
       "1      2       18     25.0        1       18\n",
       "2      3       16     30.0        1       16\n",
       "3      4        7     27.0        1        7\n",
       "4      5       58     29.0        0       58\n",
       "..   ...      ...      ...      ...      ...\n",
       "739  740       35     24.0        1       35\n",
       "740  741       35     24.0        1       35\n",
       "741  742       55     30.0        1       55\n",
       "742  743       38     32.0        1       38\n",
       "743  744       54     27.0        1       54\n",
       "\n",
       "[744 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa3d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
